{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ANN Final Project: Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T18:33:15.670464Z",
     "start_time": "2019-10-14T18:33:15.662510Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\edwin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\edwin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\edwin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\edwin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.append('cnn')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "porter = PorterStemmer()\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7260,)\n",
      "mapping done\n",
      "{'get': 0, 'times': 1, 'number': 2, 'stinking': 3, 'limitless': 4, 'kind': 5, 'cold': 6, 'flew': 7, 'leads': 8, 'air': 9, 'dawn': 10, 'memories': 11, 'dreams': 12, 'stick': 13, \"dog's\": 14, 'jojo': 15, 'suburban': 16, 'restless': 17, 'grade': 18, 'six': 19, 'rocking': 20, 'cuesto': 21, 'coca': 22, 'proceeded': 23, 'unpleasant': 24, 'near': 25, 'helloa': 26, 'story': 27, 'gas': 28, 'first': 29, 'south': 30, 'tune': 31, 'keeps': 32, 'wiping': 33, 'armchair': 34, 'yes': 35, 'kaleidoscope': 36, 'norwegian': 37, 'part': 38, 'proud': 39, 'loud': 40, 'enjoy': 41, 'knew': 42, 'dead': 43, 'market': 44, 'found': 45, 'fireside': 46, 'chop': 47, 'able': 48, 'tonight': 49, 'flowing': 50, 'bright': 51, 'neighbors': 52, 'paper': 53, 'vont': 54, 'anyway': 55, 'ride': 56, 'voices': 57, 'turning': 58, 'imitate': 59, 'hah': 60, 'wings': 61, \"daddy's\": 62, 'saying': 63, 'dance': 64, 'sunshine': 65, 'burns': 66, 'keep': 67, 'production': 68, 'certain': 69, 'anymore': 70, 'steal': 71, 'said': 72, 'juba': 73, \"we'll\": 74, \"money's\": 75, 'hmm': 76, 'lane': 77, 'feeling': 78, 'fire': 79, 'changed': 80, 'meadows': 81, 'michelle': 82, 'letter': 83, 'foot': 84, 'future': 85, 'tumble': 86, 'stars': 87, 'enough': 88, 'elementary': 89, 'little': 90, 'around': 91, 'aaaaaahhhhhh': 92, 'longer': 93, 'hourglass': 94, 'jar': 95, 'behind': 96, 'floor': 97, 'change': 98, 'lullaby': 99, 'low': 100, 'came': 101, 'fly': 102, 'shoeshine': 103, 'killer': 104, 'monkey': 105, 'row': 106, 'priestess': 107, 'roundabout': 108, 'joa': 109, 'pepper': 110, 'whisper': 111, 'skip': 112, 'black': 113, 'remember': 114, 'compare': 115, 'sce': 116, 'wind': 117, 'curse': 118, 'disease': 119, 'hears': 120, 'greet': 121, 'weight': 122, 'cha': 123, 'buys': 124, \"di'n'di\": 125, 'silver': 126, 'shop': 127, 'attracts': 128, 'chance': 129, 'quiet': 130, 'something': 131, 'took': 132, 'magazine': 133, 'face': 134, 'belong': 135, 'laughter': 136, 'ground': 137, 'greed': 138, 'takes': 139, 'diamond': 140, 'find': 141, 'indicate': 142, 'lies': 143, 'known': 144, 'talk': 145, 'shake': 146, 'parasol': 147, \"they're\": 148, 'tanta': 149, \"mem'ries\": 150, 'news': 151, 'try': 152, 'every': 153, 'bloody': 154, 'joker': 155, 'sun': 156, 'seven': 157, 'shade': 158, 'obscene': 159, 'collapsed': 160, 'lot': 161, 'nurse': 162, 'eleanor': 163, 'music': 164, 'high': 165, 'laundromat': 166, 'shades': 167, 'pigs': 168, 'even': 169, 'needed': 170, 'trim': 171, 'hope': 172, 'water': 173, 'vain': 174, 'hour': 175, 'rope': 176, 'slither': 177, 'college': 178, 'right': 179, 'villain': 180, \"'cause\": 181, 'hot': 182, 'semolina': 183, 'barrow': 184, 'grow': 185, 'break': 186, 'bla': 187, 'better': 188, 'regret': 189, 'boom': 190, 'jones': 191, 'aaaaaaaahhhh': 192, 'clowns': 193, 'shines': 194, 'shall': 195, 'pretend': 196, 'joo': 197, 'hare': 198, 'tower': 199, \"there's\": 200, 'box': 201, 'day': 202, 'sty': 203, 'surely': 204, 'magill': 205, 'maintains': 206, \"'til\": 207, 'gently': 208, 'thumb': 209, 'noise': 210, 'destruction': 211, 'stand': 212, 'someday': 213, 'sucks': 214, 'corporation': 215, 'gonna': 216, 'earned': 217, 'past': 218, 'hall': 219, 'fighting': 220, 'weeps': 221, 'walking': 222, 'beg': 223, 'like': 224, 'rival': 225, 'band': 226, 'shears': 227, 'trust': 228, 'fragrant': 229, 'moscow': 230, 'believing': 231, 'fell': 232, 'hula': 233, 'football': 234, 'poe': 235, 'quizzical': 236, 'darning': 237, 'danced': 238, 'ooh': 239, 'controlled': 240, 'gets': 241, 'penny': 242, 'drinking': 243, 'solitude': 244, 'coral': 245, 'brother': 246, 'blow': 247, 'ever': 248, 'homeward': 249, 'rigby': 250, 'pain': 251, 'feel': 252, 'stare': 253, 'cave': 254, 'changes': 255, 'hills': 256, 'doc': 257, 'fortune': 258, 'creeps': 259, 'raccoon': 260, 'polythene': 261, 'boatswain': 262, 'pocket': 263, 'peaked': 264, \"jeweler's\": 265, 'suddenly': 266, 'waves': 267, \"that's\": 268, 'machine': 269, 'away': 270, 'quando': 271, 'sang': 272, 'needs': 273, 'perverted': 274, 'work': 275, 'might': 276, 'childlike': 277, 'booked': 278, 'climb': 279, 'saw': 280, 'judge': 281, 'clouds': 282, 'missing': 283, 'sideboard': 284, 'meant': 285, 'possessing': 286, 'eight': 287, 'blew': 288, 'crime': 289, 'ice': 290, 'selling': 291, 'pouring': 292, 'wants': 293, 'lovely': 294, 'boat': 295, 'pleasing': 296, 'sounds': 297, 'head': 298, 'losing': 299, 'free': 300, 'tea': 301, 'tuesday': 302, 'worries': 303, 'hill': 304, 'leaving': 305, 'kissing': 306, 'handy': 307, 'mind': 308, 'meaning': 309, \"he's\": 310, 'wonderful': 311, 'listen': 312, 'matches': 313, 'late': 314, 'middle': 315, 'crawled': 316, 'changing': 317, 'going': 318, 'raincoats': 319, 'gumboot': 320, 'whats': 321, 'endless': 322, 'lorry': 323, 'imagine': 324, 'negotiations': 325, 'girls': 326, 'taxman': 327, 'nobody': 328, 'chuck': 329, 'science': 330, 'spoke': 331, 'say': 332, 'valentine': 333, 'lie': 334, 'woke': 335, 'strawberry': 336, 'gin': 337, 'would': 338, 'sweet': 339, 'trees': 340, 'fish': 341, \"sunday's\": 342, 'coaster': 343, 'loner': 344, 'disappear': 345, 'stay': 346, 'fuse': 347, 'give': 348, 'returning': 349, 'upstairs': 350, 'certainly': 351, 'eiffel': 352, 'towering': 353, 'yesterday': 354, 'equipped': 355, 'sorrow': 356, 'ringing': 357, 'car': 358, 'skin': 359, 'bus': 360, 'joan': 361, 'ask': 362, 'raise': 363, 'innocence': 364, 'arriving': 365, 'lasts': 366, 'disconnect': 367, 'started': 368, 'pony': 369, 'gallery': 370, 'boy': 371, 'forever': 372, 'naughty': 373, 'bup': 374, 'policeman': 375, 'hair': 376, 'tray': 377, 'gum': 378, 'river': 379, 'warning': 380, 'think': 381, 'chorus': 382, 'afraid': 383, 'speed': 384, 'hearing': 385, 'turn': 386, 'wonders': 387, 'sont': 388, 'slept': 389, 'kilt': 390, 'heard': 391, 'ocean': 392, 'countries': 393, 'hearted': 394, 'diller': 395, \"rocky's\": 396, 'rather': 397, 'hurry': 398, 'evolution': 399, 'bye': 400, 'shelter': 401, 'point': 402, 'grabbed': 403, 'ring': 404, 'brings': 405, 'looks': 406, 'tears': 407, 'clear': 408, 'turnstile': 409, 'pay': 410, 'beside': 411, 'monday': 412, 'says': 413, 'buried': 414, 'anywhere': 415, 'red': 416, 'leave': 417, 'listens': 418, 'earn': 419, 'state': 420, 'see': 421, 'magic': 422, 'colder': 423, \"i've\": 424, 'woman': 425, 'lives': 426, 'care': 427, 'waits': 428, 'cornflake': 429, 'bottle': 430, 'stupid': 431, 'church': 432, 'glad': 433, 'answer': 434, 'lil': 435, 'lup': 436, 'dragged': 437, 'walks': 438, \"someone's\": 439, 'cable': 440, 'seemed': 441, 'drink': 442, 'join': 443, 'golden': 444, 'alright': 445, 'alerted': 446, 'understood': 447, 'self': 448, 'isle': 449, 'save': 450, 'banks': 451, 'friend': 452, 'moment': 453, 'places': 454, 'bien': 455, 'jackboots': 456, 'bells': 457, 'chewing': 458, 'mending': 459, 'servicible': 460, 'fields': 461, 'feels': 462, 'believe': 463, 'situation': 464, 'make': 465, 'working': 466, 'gee': 467, 'hunger': 468, 'greetings': 469, 'deva': 470, 'doors': 471, 'take': 472, 'dreadful': 473, 'tan': 474, 'closed': 475, 'girl': 476, 'pararazzi': 477, 'desmond': 478, 'fishwife': 479, 'per': 480, 'comrade': 481, 'dressed': 482, 'queen': 483, 'turns': 484, 'perfectly': 485, 'guitar': 486, 'garden': 487, 'dime': 488, 'drag': 489, 'van': 490, 'sweater': 491, 'kill': 492, 'revolution': 493, 'laugh': 494, 'fireman': 495, 'mundo': 496, \"tuesday's\": 497, 'lend': 498, 'told': 499, 'grass': 500, 'hoping': 501, 'fix': 502, 'apart': 503, 'bag': 504, 'tried': 505, 'saved': 506, 'heba': 507, 'green': 508, 'catch': 509, 'wears': 510, 'sgt': 511, 'lends': 512, 'dirty': 513, 'tax': 514, 'younger': 515, 'roar': 516, 'remain': 517, 'minute': 518, 'hide': 519, 'sermon': 520, 'assured': 521, 'blue': 522, 'shine': 523, 'calling': 524, 'morning': 525, 'hideaway': 526, 'heaven': 527, 'guaranteed': 528, 'twist': 529, 'short': 530, 'mornings': 531, 'belle': 532, 'book': 533, 'happiness': 534, 'defelice': 535, 'lived': 536, 'worry': 537, 'need': 538, 'caught': 539, 'instead': 540, 'let': 541, 'happy': 542, 'lets': 543, 'aye': 544, 'thankful': 545, 'hilt': 546, 'many': 547, 'stating': 548, 'lucy': 549, 'dripping': 550, 'talking': 551, 'nothing': 552, 'hanging': 553, 'war': 554, 'eat': 555, \"they'd\": 556, 'single': 557, 'seems': 558, 'chairman': 559, 'lover': 560, 'lips': 561, 'skies': 562, 'yellow': 563, 'possessions': 564, 'sky': 565, 'socks': 566, 'majoring': 567, \"majesty's\": 568, 'place': 569, \"mother's\": 570, 'digging': 571, 'daniel': 572, 'filter': 573, 'penguin': 574, 'rest': 575, 'compares': 576, 'house': 577, 'spinning': 578, 'share': 579, 'till': 580, 'held': 581, 'mucho': 582, 'ene': 583, 'dream': 584, 'corner': 585, 'wishing': 586, 'diverted': 587, 'tres': 588, 'audience': 589, 'measured': 590, 'recall': 591, 'gideon': 592, 'getting': 593, 'kid': 594, 'help': 595, 'earth': 596, 'fill': 597, 'awoke': 598, 'everywhere': 599, 'molly': 600, 'sailed': 601, 'celebrations': 602, 'broken': 603, 'really': 604, 'mao': 605, 'road': 606, 'ferdy': 607, 'invitations': 608, 'hat': 609, 'anything': 610, 'missed': 611, 'park': 612, 'singing': 613, 'far': 614, 'knock': 615, 'saving': 616, 'melting': 617, 'arizona': 618, 'neighborhood': 619, 'parted': 620, 'tomorrow': 621, 'across': 622, 'flat': 623, 'hog': 624, 'white': 625, 'thoughts': 626, 'dot': 627, 'pleasure': 628, 'class': 629, \"feelin'\": 630, 'fancy': 631, 'song': 632, 'flowers': 633, 'bathroom': 634, 'mac': 635, 'cracker': 636, 'appear': 637, 'painting': 638, 'straight': 639, 'poppies': 640, 'moments': 641, 'ensemble': 642, 'kept': 643, 'got': 644, 'mean': 645, 'snow': 646, 'acts': 647, 'les': 648, 'pam': 649, 'paul': 650, 'cocker': 651, 'holding': 652, 'wow': 653, 'seat': 654, 'sure': 655, 'mother': 656, 'walter': 657, 'realized': 658, 'built': 659, 'texpert': 660, 'thinking': 661, 'eyes': 662, 'sixty': 663, 'tangerine': 664, 'krishna': 665, 'jackknife': 666, 'await': 667, 'makes': 668, 'shore': 669, 'nine': 670, 'city': 671, 'engine': 672, 'bath': 673, 'daisy': 674, 'nearly': 675, 'showdown': 676, 'feet': 677, 'wink': 678, 'anyhow': 679, 'smokers': 680, 'lovers': 681, 'thousand': 682, 'loretta': 683, 'driving': 684, 'thrill': 685, 'marmalade': 686, 'woo': 687, 'works': 688, 'cottage': 689, 'inverted': 690, 'images': 691, 'cool': 692, 'darling': 693, 'lead': 694, 'martin': 695, 'radiate': 696, 'sack': 697, 'equal': 698, 'brain': 699, 'tells': 700, 'town': 701, 'moved': 702, 'train': 703, 'week': 704, 'cried': 705, 'hit': 706, 'pink': 707, 'loved': 708, 'farm': 709, 'steady': 710, 'undying': 711, 'fountain': 712, 'troubles': 713, 'wrong': 714, 'independence': 715, 'poop': 716, \"maxwell's\": 717, 'ran': 718, 'waiting': 719, 'spinal': 720, 'left': 721, 'unfold': 722, 'bompa': 723, 'getter': 724, 'walked': 725, \"m'mm\": 726, 'shouts': 727, 'celebrate': 728, 'somebody': 729, 'back': 730, 'spent': 731, 'shoulder': 732, \"nothing's\": 733, 'nose': 734, 'king': 735, 'mistake': 736, 'west': 737, 'whenever': 738, 'rocky': 739, 'anyone': 740, 'made': 741, 'gives': 742, 'putting': 743, 'photographs': 744, 'else': 745, 'smoke': 746, 'miles': 747, 'gave': 748, 'drew': 749, 'knit': 750, 'arise': 751, 'old': 752, 'walrus': 753, 'buy': 754, 'station': 755, 'child': 756, 'watching': 757, 'woof': 758, 'knee': 759, 'clean': 760, 'unpack': 761, 'stays': 762, 'cake': 763, 'window': 764, 'somewhere': 765, 'storm': 766, 'gone': 767, 'load': 768, 'aaaaahhhhhhhhhh': 769, 'advice': 770, 'pride': 771, 'winter': 772, 'people': 773, 'feelings': 774, 'sees': 775, 'prudence': 776, 'notice': 777, 'street': 778, 'movement': 779, 'night': 780, 'quarter': 781, 'crowd': 782, 'sweeping': 783, 'hands': 784, 'phone': 785, 'act': 786, 'faces': 787, 'ways': 788, 'understands': 789, 'yard': 790, 'disagree': 791, 'puts': 792, 'incredibly': 793, 'cos': 794, 'bring': 795, 'ship': 796, 'twenty': 797, 'friends': 798, 'tear': 799, 'pick': 800, 'aware': 801, 'affection': 802, 'holes': 803, 'thought': 804, 'tryin': 805, 'man': 806, 'universe': 807, 'sound': 808, 'fall': 809, 'dies': 810, 'marketplace': 811, 'qui': 812, 'lancashire': 813, 'nice': 814, 'sung': 815, 'guess': 816, 'put': 817, 'chicka': 818, 'worked': 819, 'dirt': 820, 'lose': 821, 'orange': 822, 'nights': 823, 'asked': 824, 'stretches': 825, 'apologize': 826, 'carat': 827, 'comes': 828, 'latches': 829, 'words': 830, 'learn': 831, 'showed': 832, 'hear': 833, 'telling': 834, 'new': 835, 'rice': 836, 'slip': 837, 'always': 838, 'open': 839, 'named': 840, 'tired': 841, \"day's\": 842, 'look': 843, 'young': 844, 'along': 845, 'line': 846, \"anybody's\": 847, 'endear': 848, 'resting': 849, 'bang': 850, 'moves': 851, 'choking': 852, 'edgar': 853, 'miss': 854, 'allen': 855, 'blink': 856, 'sits': 857, \"girl's\": 858, 'looked': 859, 'everybody': 860, 'full': 861, 'inviting': 862, 'babe': 863, 'guru': 864, 'ahead': 865, 'set': 866, 'pilchard': 867, 'nowhere': 868, 'laughing': 869, 'expert': 870, 'standing': 871, 'end': 872, 'game': 873, 'round': 874, 'tucson': 875, 'sharing': 876, 'store': 877, 'big': 878, 'hole': 879, 'drop': 880, 'wine': 881, 'wait': 882, 'aboard': 883, 'mattered': 884, 'pennies': 885, 'sleep': 886, 'count': 887, 'call': 888, 'dew': 889, 'carrying': 890, 'thirty': 891, 'wildly': 892, 'wake': 893, 'chain': 894, 'command': 895, 'weeds': 896, 'policemen': 897, 'view': 898, 'goodbye': 899, 'sending': 900, 'shot': 901, 'write': 902, 'log': 903, 'thing': 904, 'match': 905, 'hand': 906, 'sincerely': 907, 'burning': 908, 'misunderstanding': 909, 'albert': 910, 'fool': 911, 'shoulders': 912, 'flight': 913, 'seventeen': 914, 'paramucho': 915, 'cloudy': 916, 'goo': 917, 'heat': 918, 'live': 919, 'bible': 920, 'shoot': 921, 'must': 922, 'living': 923, 'spending': 924, 'postcards': 925, 'hela': 926, 'muddy': 927, 'ono': 928, 'sunny': 929, 'wood': 930, 'ready': 931, \"groovin'\": 932, 'beneath': 933, 'drive': 934, 'doubt': 935, 'loves': 936, 'million': 937, 'hell': 938, 'clubs': 939, 'close': 940, 'doctor': 941, 'send': 942, 'everyone': 943, 'birthday': 944, 'touch': 945, 'pornographic': 946, 'rent': 947, 'film': 948, 'loving': 949, 'evermore': 950, \"mama's\": 951, 'maxwell': 952, 'joke': 953, 'nineteen': 954, 'singer': 955, 'spoon': 956, 'canary': 957, 'looking': 958, 'everything': 959, 'picture': 960, 'went': 961, 'scrimp': 962, 'plan': 963, 'riding': 964, 'start': 965, 'quit': 966, 'woah': 967, 'true': 968, 'taught': 969, 'grinning': 970, 'legs': 971, 'sir': 972, 'saloon': 973, 'dark': 974, 'party': 975, 'banker': 976, 'contribution': 977, 'worth': 978, 'mojo': 979, 'kiss': 980, 'know': 981, 'spaniel': 982, 'father': 983, 'valerie': 984, 'bought': 985, 'shaves': 986, 'california': 987, 'blackburn': 988, 'rolling': 989, 'leisure': 990, 'sheepdog': 991, 'lost': 992, 'born': 993, 'promises': 994, 'danny': 995, 'school': 996, 'top': 997, 'chasing': 998, 'show': 999, 'died': 1000, 'bob': 1001, 'eggman': 1002, 'bags': 1003, 'wipe': 1004, 'hate': 1005, 'fine': 1006, 'kicking': 1007, 'flown': 1008, 'bullfrog': 1009, 'tree': 1010, 'baby': 1011, 'clue': 1012, 'blows': 1013, 'taxis': 1014, 'roof': 1015, \"pepper's\": 1016, 'used': 1017, 'eggmen': 1018, 'yay': 1019, 'billy': 1020, 'slowly': 1021, 'learning': 1022, 'trolley': 1023, 'bra': 1024, 'wild': 1025, 'burst': 1026, 'front': 1027, 'pool': 1028, \"your's\": 1029, 'appreciate': 1030, 'sorry': 1031, 'stop': 1032, 'lifetime': 1033, 'revival': 1034, 'beautiful': 1035, 'drift': 1036, 'case': 1037, 'stared': 1038, 'hammer': 1039, 'weeks': 1040, \"i'm\": 1041, 'turned': 1042, 'winding': 1043, 'speaking': 1044, 'vera': 1045, 'hurting': 1046, 'sister': 1047, 'max': 1048, 'sometimes': 1049, 'submarine': 1050, 'shadow': 1051, 'guy': 1052, 'caressing': 1053, \"i'll\": 1054, 'plasticine': 1055, 'slow': 1056, 'special': 1057, 'awake': 1058, \"octopus'\": 1059, 'vanish': 1060, 'two': 1061, 'postcard': 1062, 'sight': 1063, 'forget': 1064, 'jude': 1065, 'world': 1066, 'die': 1067, 'running': 1068, 'tell': 1069, 'brown': 1070, 'begin': 1071, 'key': 1072, 'coat': 1073, 'mama': 1074, 'suns': 1075, \"everybody's\": 1076, 'blind': 1077, 'miami': 1078, 'blackbird': 1079, 'refrain': 1080, 'motorcar': 1081, 'haze': 1082, 'eyeballs': 1083, 'fair': 1084, 'warm': 1085, 'wall': 1086, 'doo': 1087, 'year': 1088, 'roller': 1089, 'studied': 1090, 'cut': 1091, 'pretty': 1092, 'anytime': 1093, 'dose': 1094, 'minds': 1095, 'joy': 1096, 'cellophane': 1097, 'plays': 1098, 'dakota': 1099, 'tacks': 1100, 'declare': 1101, 'stood': 1102, 'dig': 1103, 'although': 1104, 'years': 1105, 'goes': 1106, 'bed': 1107, 'sings': 1108, 'name': 1109, 'shown': 1110, 'falling': 1111, 'fun': 1112, 'way': 1113, \"singer's\": 1114, 'bellyful': 1115, 'children': 1116, 'win': 1117, 'satisfied': 1118, 'glass': 1119, 'asking': 1120, 'follow': 1121, 'anybody': 1122, \"they've\": 1123, 'money': 1124, 'mots': 1125, 'frightened': 1126, 'sleeping': 1127, 'john': 1128, 'obrigado': 1129, 'department': 1130, 'wave': 1131, 'feed': 1132, 'hoe': 1133, 'checked': 1134, 'protected': 1135, 'biding': 1136, 'since': 1137, 'picks': 1138, 'nancy': 1139, 'teachers': 1140, 'upset': 1141, 'stops': 1142, 'note': 1143, 'holy': 1144, \"junior's\": 1145, 'calls': 1146, 'quite': 1147, 'cloud': 1148, 'one': 1149, 'together': 1150, 'hard': 1151, 'couple': 1152, 'step': 1153, 'test': 1154, 'corazon': 1155, 'pies': 1156, 'roses': 1157, 'downstairs': 1158, 'crying': 1159, 'bit': 1160, 'constitution': 1161, 'run': 1162, 'agree': 1163, 'home': 1164, 'sleeps': 1165, \"he'd\": 1166, 'please': 1167, \"gideon's\": 1168, 'chair': 1169, 'behave': 1170, 'moon': 1171, 'institution': 1172, 'rob': 1173, 'junior': 1174, 'birds': 1175, 'gather': 1176, 'safe': 1177, 'sad': 1178, 'jam': 1179, 'drank': 1180, 'time': 1181, 'often': 1182, 'never': 1183, 'easy': 1184, 'jukebox': 1185, 'fed': 1186, 'another': 1187, 'lifting': 1188, 'much': 1189, 'raleigh': 1190, 'things': 1191, 'meanwhile': 1192, 'good': 1193, 'brotherhood': 1194, 'could': 1195, 'lucky': 1196, 'dreamer': 1197, 'style': 1198, 'pictures': 1199, 'oan': 1200, 'blindly': 1201, 'pools': 1202, \"we've\": 1203, 'hey': 1204, 'called': 1205, 'play': 1206, 'early': 1207, 'clothes': 1208, 'dancer': 1209, 'learns': 1210, 'bad': 1211, 'boys': 1212, 'edison': 1213, 'rain': 1214, 'grave': 1215, 'dear': 1216, 'windy': 1217, 'peace': 1218, 'trouble': 1219, 'ago': 1220, 'cup': 1221, 'comb': 1222, 'happen': 1223, 'mine': 1224, 'funny': 1225, 'complaining': 1226, 'cry': 1227, \"we'd\": 1228, 'climbing': 1229, 'read': 1230, 'owww': 1231, 'washed': 1232, 'seeing': 1233, \"she'd\": 1234, 'inciting': 1235, 'darkness': 1236, 'wonder': 1237, 'hurt': 1238, 'opened': 1239, 'avoid': 1240, 'understand': 1241, 'likes': 1242, \"balalaika's\": 1243, 'jobber': 1244, 'mustard': 1245, 'well': 1246, 'grandchildren': 1247, 'sing': 1248, 'upon': 1249, 'cat': 1250, 'marshmallow': 1251, 'reason': 1252, 'rushes': 1253, 'lords': 1254, 'five': 1255, 'slumbers': 1256, \"can't\": 1257, \"we're\": 1258, 'though': 1259, 'hold': 1260, 'days': 1261, 'perform': 1262, 'noticed': 1263, 'tight': 1264, \"goin'\": 1265, 'meander': 1266, 'wisdom': 1267, 'room': 1268, 'nah': 1269, 'almost': 1270, 'table': 1271, 'knows': 1272, 'wear': 1273, 'swim': 1274, 'sail': 1275, 'ties': 1276, 'seconds': 1277, 'ussr': 1278, 'submarines': 1279, 'belonged': 1280, 'hee': 1281, 'grin': 1282, 'brand': 1283, 'love': 1284, 'walk': 1285, 'teacher': 1286, 'lagoon': 1287, 'rug': 1288, 'sat': 1289, 'matter': 1290, 'screaming': 1291, 'wedding': 1292, 'summer': 1293, 'done': 1294, 'light': 1295, 'real': 1296, 'foolish': 1297, 'may': 1298, 'seen': 1299, 'shows': 1300, 'ease': 1301, 'ukraine': 1302, 'lit': 1303, 'stoney': 1304, 'begins': 1305, 'smiles': 1306, 'letters': 1307, 'local': 1308, 'eye': 1309, 'older': 1310, 'woos': 1311, 'met': 1312, 'form': 1313, 'dave': 1314, 'cola': 1315, 'police': 1316, 'hello': 1317, 'captain': 1318, 'beyond': 1319, 'long': 1320, 'horse': 1321, 'come': 1322, 'crabalocker': 1323, 'rock': 1324, 'yeah': 1325, 'alone': 1326, 'pataphysical': 1327, 'toe': 1328, 'mary': 1329, 'moan': 1330, 'plans': 1331, 'inside': 1332, 'sunday': 1333, 'dog': 1334, 'fools': 1335, 'keeping': 1336, \"somethin'\": 1337, 'sweaty': 1338, 'knowing': 1339, 'life': 1340, 'showing': 1341, 'snide': 1342, 'insecure': 1343, 'closer': 1344, 'evening': 1345, 'wearing': 1346, 'rose': 1347, 'english': 1348, 'religion': 1349, 'wasting': 1350, 'wigwam': 1351, 'fifteen': 1352, 'carry': 1353, 'joob': 1354, 'hearts': 1355, 'medicine': 1356, 'customer': 1357, 'dan': 1358, 'syndicate': 1359, 'hoop': 1360, 'kids': 1361, 'fussing': 1362, 'writing': 1363, 'shining': 1364, 'word': 1365, 'photograph': 1366, 'diamonds': 1367, 'club': 1368, 'bridge': 1369, 'amore': 1370, 'beach': 1371, \"ain't\": 1372, 'broke': 1373, 'cent': 1374, 'knickers': 1375, 'still': 1376, 'wight': 1377, 'smile': 1378, 'harm': 1379, 'lonely': 1380, 'talked': 1381, 'job': 1382, 'ears': 1383, 'tenderly': 1384, 'best': 1385, 'laughs': 1386, 'sergeant': 1387, 'jai': 1388, 'mckenzie': 1389, 'door': 1390, 'stands': 1391, 'annoyed': 1392, 'aaaaaaahhhh': 1393, 'scratch': 1394, \"i'd\": 1395, 'newspaper': 1396, 'crossed': 1397, 'portrait': 1398, 'fifty': 1399, 'lights': 1400, 'half': 1401, 'strange': 1402, 'hoo': 1403, \"georgia's\": 1404, 'drifting': 1405, 'precisely': 1406, 'appears': 1407, 'heart': 1408, 'cigarette': 1409, 'solution': 1410, 'hung': 1411, 'shout': 1412, 'promise': 1413, 'last': 1414, 'want': 1415, 'today': 1416, 'insane': 1417, 'carousel': 1418, 'gun': 1419, 'penetrate': 1420, 'sunken': 1421, 'soon': 1422, 'someone': 1423, 'land': 1424, 'porters': 1425, 'shirt': 1426, 'sea': 1427, 'barber': 1428, 'deny': 1429, 'tube': 1430, 'shady': 1431, 'happens': 1432, 'whoa': 1433, 'sitting': 1434, 'sold': 1435, 'rise': 1436, 'fears': 1437, 'next': 1438, 'pillow': 1439, 'risk': 1440, 'honey': 1441, 'somehow': 1442, 'four': 1443, 'coming': 1444, 'ten': 1445, 'bom': 1446, 'roll': 1447, 'limousine': 1448, 'bulldog': 1449, 'stealing': 1450, 'boac': 1451, 'attractively': 1452, 'mountain': 1453, 'introduce': 1454, 'investigation': 1455, 'winging': 1456, 'sit': 1457, 'three': 1458, 'bird': 1459, 'small': 1460, 'custard': 1461, 'testimonial': 1462, 'finger': 1463, 'army': 1464, 'making': 1465, 'lock': 1466}\n",
      "generated0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated1000 tokens\n",
      "generated2000 tokens\n",
      "generated3000 tokens\n",
      "generated4000 tokens\n",
      "generated5000 tokens\n",
      "generated6000 tokens\n",
      "generated7000 tokens\n",
      "training data generated\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 244. MiB for an array with shape (43548, 1467) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 119>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m word_to_id, id_to_word \u001b[38;5;241m=\u001b[39m mapping(tokens)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(word_to_id)\n\u001b[1;32m--> 119\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_to_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m#print(np.shape(X))\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m#print(np.shape(y))\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mgenerate_training_data\u001b[1;34m(tokens, word_to_id, window)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m tokens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining data generated\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(y)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 244. MiB for an array with shape (43548, 1467) and data type int32"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow.keras\n",
    "'''\n",
    "data = pd.read_csv('CNN_Articels_clean.csv')\n",
    "text = pd.DataFrame(data, columns=['Article text'])\n",
    "text_np = pd.DataFrame.to_numpy(text)\n",
    "'''\n",
    "lyrics_file = open('beatles.txt', 'r')\n",
    "text = lyrics_file.read()\n",
    "lyrics_file.close()\n",
    "\n",
    "def tokenize(text):\n",
    "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
    "    return pattern.findall(text.lower())\n",
    "\n",
    "def preprocess(tokens):\n",
    "    tokens_processed = []\n",
    "    for words in tokens:\n",
    "        if words in stop_words:\n",
    "            continue\n",
    "        if len(words) <= 2:\n",
    "            continue\n",
    "\n",
    "        tokens_processed.append(words)\n",
    "\n",
    "    return tokens_processed\n",
    "\n",
    "def mapping(tokens):\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "\n",
    "    for i, token in enumerate(set(tokens)):\n",
    "        word_to_id[token] = i\n",
    "        id_to_word[i] = token\n",
    "\n",
    "    print('mapping done')\n",
    "\n",
    "    return word_to_id, id_to_word\n",
    "\n",
    "\n",
    "def generate_training_data(tokens, word_to_id, window):\n",
    "    X = []\n",
    "    y = []\n",
    "    n_tokens = len(tokens)\n",
    "\n",
    "    for i in range(n_tokens):\n",
    "        idx = concat(\n",
    "            range(max(0, i - window), i),\n",
    "            range(i, min(n_tokens, i + window + 1))\n",
    "        )\n",
    "        i_id = word_to_id[tokens[i]]\n",
    "        for j in idx:\n",
    "            if i == j:\n",
    "                continue\n",
    "            X.append(one_hot_encode(i_id, len(word_to_id)))\n",
    "            y.append(one_hot_encode(word_to_id[tokens[j]], len(word_to_id)))\n",
    "\n",
    "        if i%1000 == 0:\n",
    "            print('generated'+ str(i) +' tokens')\n",
    "\n",
    "    print('training data generated')\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "def concat(*iterables):\n",
    "    for iterable in iterables:\n",
    "        yield from iterable\n",
    "\n",
    "\n",
    "def one_hot_encode(id, vocab_size):\n",
    "    res = [0] * vocab_size\n",
    "    res[id] = 1\n",
    "    return res\n",
    "\n",
    "tokens = preprocess(tokenize(text))\n",
    "\n",
    "#tokens = preprocess(tokenize(str(text_np[1])))\n",
    "\n",
    "'''\n",
    "for i in range(40):\n",
    "    tokens += preprocess(tokenize(str(text_np[i+2])))\n",
    "'''\n",
    "print(np.shape(tokens))\n",
    "\n",
    "\"\"\"\n",
    "tokens = list(map(lemmatizer.lemmatize, tokens))\n",
    "for words in tokens:\n",
    "    if(words in stop_words):\n",
    "        tokens.remove(words)\n",
    "    elif(len(words) < 3):\n",
    "        tokens.remove(words)\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "\n",
    "#tokens = lemmatizer.lemmatize(tokens)\n",
    "\n",
    "for i in range(15):\n",
    "    temp_tokens = tokenize(str(text_np[i+2]))\n",
    "    temp_tokens = list(map(lemmatizer.lemmatize, temp_tokens))\n",
    "\n",
    "    for word in temp_tokens:\n",
    "        if(word in stop_words):\n",
    "            temp_tokens.remove(word)\n",
    "        elif(len(word) < 3):\n",
    "            temp_tokens.remove(word)\n",
    "    tokens += temp_tokens\n",
    "\n",
    "    print('tokenization #' + str(i))\n",
    "\"\"\"\n",
    "word_to_id, id_to_word = mapping(tokens)\n",
    "print(word_to_id)\n",
    "\n",
    "\n",
    "X, y = generate_training_data(tokens, word_to_id, 3)\n",
    "\n",
    "\n",
    "\n",
    "#print(np.shape(X))\n",
    "#print(np.shape(y))\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_neurons = X.shape[1]\n",
    "print(num_neurons)\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, input_dim=num_neurons, activation='relu'))\n",
    "model.add(keras.layers.Dense(num_neurons, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=50, batch_size=128)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model2 = keras.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "x_enc = model2.predict(X)\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = word_to_id.get('love')\n",
    "print(index)\n",
    "a = model.predict(X[index:index+1])\n",
    "\n",
    "b = list(np.argsort(a)[0])[0:10]\n",
    "print(b)\n",
    "\n",
    "\n",
    "for p in range(10):\n",
    "    print(id_to_word.get(b[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "v1 = model2.predict(X[index:index+1])\n",
    "\n",
    "idx = word_to_id.get('like')\n",
    "v2 = model2.predict(X[idx:idx+1])\n",
    "\n",
    "#print(v1)\n",
    "#print(v2)\n",
    "print(np.linalg.norm(v2-v1))\n",
    "\n",
    "idk = word_to_id.get('gun')\n",
    "v3 = model2.predict(X[idk:idk+1])\n",
    "\n",
    "#print(v3)\n",
    "print(np.linalg.norm(v3-v1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_vectors = []\n",
    "\n",
    "for i in range(num_neurons):\n",
    "    word_vectors.append(one_hot_encode(i, num_neurons))\n",
    "\n",
    "word_vectors = np.array(word_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "enc = model2.predict(word_vectors)\n",
    "enc.shape\n",
    "\n",
    "print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = list()\n",
    "target = np.array(enc[word_to_id.get('yesterday')])\n",
    "#print(target)\n",
    "\n",
    "for i in range(num_neurons):\n",
    "    p.append(np.linalg.norm(target - np.array(enc[i])))\n",
    "\n",
    "p = np.array(p)\n",
    "a = list(np.argsort(p))\n",
    "\n",
    "lab = list()\n",
    "pp = list()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#print(a)\n",
    "for k in range(11):\n",
    "    lab.append(id_to_word.get(a[k]))\n",
    "    pp.append([p[a[k]]])\n",
    "\n",
    "plt.scatter(pp[1:], np.zeros((10)))\n",
    "print(lab)\n",
    "\n",
    "pp = np.array(pp)\n",
    "\n",
    "for k in range(1, 10):\n",
    "    plt.annotate(lab[k], (pp[k], 0.003 * k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
